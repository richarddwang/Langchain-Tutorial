{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Query Rewrite\n",
    "é€éå°‡å•é¡Œ (query) æ”¹å¯«ï¼Œæå‡æ–‡ä»¶æŠ½å– (document retrieval) çš„æ€§èƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 MultiQuery\n",
    "é¢å°ä¸‹é¢å…©å€‹ç—›é»ï¼š\n",
    "- äººé¡çœ‹èµ·ä¾† query ä¸­çš„ä¸€å°é»æªè¾­çš„æ”¹è®Šï¼Œä¹Ÿå¯èƒ½æœƒå½±éŸ¿æ–‡ä»¶æŠ½å–çš„çµæœï¼Œå°è‡´éœ€è¦å˜—è©¦ä¸åŒçš„ query (prompt tuning)\n",
    "- embeddings æ²’è¾¦æ³•å®Œæ•´åœ°æ•æ‰æ‰€æœ‰ query ä¸­çš„æ„æ€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘å€‘å¯ä»¥å˜—è©¦:\n",
    "1. æ ¹æ“šä½¿ç”¨è€…çš„ queryï¼Œç”¢ç”Ÿå¤šå€‹é—œæ³¨ä¸åŒé¢å‘çš„æ›¿ä»£ query\n",
    "2. ä¾æ“šå„å€‹ query ç¨ç«‹æŠ½å–æ–‡ä»¶\n",
    "3. å°‡å„å€‹ query æŠ½å–å‡ºçš„æ–‡ä»¶é›†åˆä½µä¸¦å»é‡è¤‡ (unique union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_setup import ChatOpenAI, pprint_documents, tracing_v2_enabled_if_api_key_set\n",
    "\n",
    "# è®€å–è³‡æ–™\n",
    "loader = NotionDirectoryLoader(\"../../data/notion/\")\n",
    "documents = loader.load()\n",
    "\n",
    "# åˆ†å‰²æ–‡ä»¶ (Document)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# VectorDB\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Qdrant.from_documents(documents=splits, embedding=embedding, location=\":memory:\")\n",
    "\n",
    "# å»ºç«‹ MultiQueryRetriever\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k': 2}), llm=llm\n",
    ")\n",
    "\n",
    "# ç´€éŒ„ (logging) å…§éƒ¨ç”¢ç”Ÿçš„å•é¡Œ (queries)\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•çš„å®šç¾©æ˜¯ä»€éº¼ï¼Ÿ', '2. éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•æœ‰å“ªäº›ç‰¹é»ï¼Ÿ', '3. éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•å¦‚ä½•æ‡‰ç”¨åœ¨å¯¦éš›é–‹ç™¼ä¸­ï¼Ÿ']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "ä»Šå¤©ä¾†ä»‹ç´¹æ—¥æœ¬æœ€å…·ä»£è¡¨æ€§çš„è»Ÿé«”é–‹ç™¼æ‰‹æ³•\n",
      "å®ƒçš„åå­ç‚º **éš•çŸ³è½ä¸‹å‹é–‹ç™¼**ã€‚\n",
      "\n",
      "# ç¬¬ä¸€ç¯€\n",
      "\n",
      "é€šå¸¸çš„**ç€‘å¸ƒå¼é–‹ç™¼**æ˜¯åƒä¸‹é¢é€™æ¨£çš„å½¢å¼:\n",
      "| æ­¥é©Ÿ | å…§å®¹     | è² è²¬äºº     |\n",
      "| ---- | -------- | ---------- |\n",
      "| 1    | è¦ä»¶å®šç¾© | Producer   |\n",
      "| 2    | åŸºæœ¬è¨­è¨ˆ | Director   |\n",
      "| 3    | è©³ç´°è¨­è¨ˆ | Planner    |\n",
      "| 4    | å¯¦è£     | Programmer |\n",
      "\n",
      "Metadata:{'source': '..\\\\..\\\\data\\\\notion\\\\éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•.md'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "è€Œ**éš•çŸ³å¼é–‹ç™¼**æ˜¯åƒä¸‹é¢é€™æ¨£å­çš„å½¢å¼ï¼š\n",
      "|     | æ­¥é©Ÿ | å…§å®¹     | è² è²¬äºº     |\n",
      "| --- | ---- | -------- | ---------- |\n",
      "| ç¥  | 1    | è¦ä»¶å®šç¾© | Producer   |\n",
      "| ç¥  | 2    | åŸºæœ¬è¨­è¨ˆ | Director   |\n",
      "| ç¥  | 3    | è©³ç´°è¨­è¨ˆ | Planner    |\n",
      "| ç¥  | 4    | å¯¦è£     | Programmer |\n",
      "\n",
      "ç„¶å¾Œå°±æœƒé€™æ¨£ï¼ˆå…¨éƒ¨éƒ½è¢«éš•çŸ³ç ¸åˆ°çˆ†ç‚¸ï¼‰ï¼š\n",
      "\n",
      "Metadata:{'source': '..\\\\..\\\\data\\\\notion\\\\éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•.md'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "ç„¶å¾Œå°±æœƒé€™æ¨£ï¼ˆå…¨éƒ¨éƒ½è¢«éš•çŸ³ç ¸åˆ°çˆ†ç‚¸ï¼‰ï¼š\n",
      "\n",
      "ğŸ’¥è¦ä»¶å®šç¾©ğŸ’¥ProducerğŸ’¥åŸºæœ¬è¨­è¨ˆğŸ’¥DirectorğŸ’¥è©³ç´°è¨­è¨ˆğŸ’¥PlannerğŸ’¥å¯¦è£ğŸ’¥Programmer\n",
      "\n",
      "é€™æ˜¯æ•æ·å¼é–‹æ³•å®ˆæ³•çš„å¾ªç’°\n",
      "\n",
      "[è¦ä»¶å®šç¾©->åŸºæœ¬è¨­è¨ˆ->è©³ç´°è¨­è¨ˆ->å¯¦è£]->[è¦ä»¶å®šç¾©->åŸºæœ¬è¨­è¨ˆ->è©³ç´°è¨­è¨ˆ->å¯¦è£]->\n",
      "\n",
      "ä½†åœ¨ç¥çš„é¢å‰éƒ½æ˜¯ç„¡åŠ›çš„ï¼ˆå…¨éƒ¨éƒ½è¢«éš•çŸ³ç ¸åˆ°çˆ†ç‚¸ï¼‰\n",
      "\n",
      "[è¦ä»¶ğŸ’¥å®šç¾©-ğŸ’¥>åŸºæœ¬è¨­è¨ˆğŸ’¥->è©³ç´°è¨­ğŸ’¥è¨ˆ->å¯¦ğŸ’¥è£]<->[è¦ä»¶å®šğŸ’¥ç¾©->åŸºæœ¬è¨­ğŸ’¥è¨ˆ->è©³ğŸ’¥ç´°è¨­ğŸ’¥è¨ˆ->ğŸ’¥å¯¦è£]->\n",
      "\n",
      "åœ¨ç¥çš„ä¸€è²ä»¤ä¸‹å…¨éƒ¨éƒ½æœƒ**å´©å£**ï¼Œ\n",
      "\n",
      "è€Œäººæ°‘æœƒåŠªåŠ›åœ°**é‡å»º**ï¼Œ\n",
      "\n",
      "é€™å°±æ˜¯ -- éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•ã€‚\n",
      "\n",
      "# ç¬¬äºŒç¯€\n",
      "\n",
      "Metadata:{'source': '..\\\\..\\\\data\\\\notion\\\\éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•.md'}\n",
      "[LangSmith URL]: https://smith.langchain.com/o/34ec837d-8405-462d-b949-fdfaebda792b/projects/p/fdcbda35-4d3a-418b-ab49-7e3205e630a6/r/4778c024-0c42-45e4-bc0a-e210e20a9404?poll=true\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled_if_api_key_set(project_name='tutorial'):\n",
    "    question = \"ä»€éº¼æ˜¯éš•çŸ³è½ä¸‹å¼é–‹ç™¼æ³•?\"\n",
    "    unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "    pprint_documents(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Self-querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç•¶é‡åˆ°ä½¿ç”¨è€…å•é¡Œ (query) éš±å«äº†é‡å°è©®é‡‹è³‡æ–™ (metadata) çš„æ¢ä»¶æ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "from langchain.chains.query_constructor.base import (\n",
    "    load_query_constructor_chain,\n",
    "    DEFAULT_EXAMPLES\n",
    ")\n",
    "\n",
    "from langchain_setup import OpenAI, pprint_documents, tracing_v2_enabled_if_api_key_set\n",
    "\n",
    "# æ–‡ä»¶ (documents)\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"rating\": 9.9,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"science fiction\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "# å»ºç«‹ Vectorstore\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Qdrant.from_documents(docs, embeddings, location=\":memory:\")\n",
    "\n",
    "# This example specifies a query and composite filter\n",
    "query = \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LangSmith URL]: https://smith.langchain.com/o/34ec837d-8405-462d-b949-fdfaebda792b/projects/p/fdcbda35-4d3a-418b-ab49-7e3205e630a6/r/acd95022-aca8-4dc9-93a4-964ba5c59103?poll=true\n",
      "Document 1:\n",
      "\n",
      "Toys come alive and have a blast doing so\n",
      "\n",
      "Metadata:{'genre': 'animated', 'year': 1995}\n"
     ]
    }
   ],
   "source": [
    "# å®šç¾©è©®é‡‹è³‡æ–™ (metadata)çš„æ¯ä¸€å€‹æ¬„ä½ (field)\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# å»ºç«‹ SelfQueryRetriever\n",
    "llm = OpenAI(temperature=0)\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "selfq_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectorstore, document_content_description, metadata_field_info, verbose=True\n",
    ")\n",
    "\n",
    "# å¯¦éš›æŠ½å– (retrieve) çœ‹çœ‹\n",
    "with tracing_v2_enabled_if_api_key_set(project_name='tutorial'):\n",
    "    selfq_retrieved_documents = selfq_retriever.get_relevant_documents(query)\n",
    "pprint_documents(selfq_retrieved_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€™åŠŸèƒ½ç”±ä¸€å€‹è¤‡é›œçš„ prompt ä¾†å¯¦ç¾ï¼Œé€™å€‹ prompt ä¾åºæä¾›äº†å¤§èªè¨€æ¨¡å‹ (LLM) ä»¥ä¸‹çš„è³‡è¨Š\n",
    "- ç›®æ¨™ï¼šå°‡ä½¿ç”¨è€…å•é¡Œçµæ§‹åŒ–ä¾†å°é½Šæä¾›çš„è³‡æ–™æ ¼å¼\n",
    "- è¼¸å‡ºæ ¼å¼èªªæ˜ (formatting instruction)\n",
    "- è§£é‡‹æœ‰å“ªäº›æ¯”è¼ƒè¨ˆç®—å­ (comparison operators) å¦‚ç­‰æ–¼ã€å¤§æ–¼ï¼Œå“ªäº›é‚è¼¯é‹ç®—å­ (logical operators) å¦‚ andã€or å¯ä»¥ç”¨ï¼Œé‚„æœ‰æ€éº¼ä½¿ç”¨\n",
    "- æ•¸å€‹ç¯„ä¾‹ï¼Œæ¯å€‹ç¯„ä¾‹åŒ…å«\n",
    "    - è³‡æ–™å…§å®¹çš„ç°¡çŸ­èªªæ˜\n",
    "    - è©®é‡‹è³‡æ–™ (metadata) æ¬„ä½ (field) çš„ä»‹ç´¹\n",
    "    - ä½¿ç”¨è€…å•é¡Œ (user query)\n",
    "    - æ¨¡å‹ç”¢å‡ºçš„çµæ§‹åŒ–çš„å›ç­”\n",
    "\n",
    "è€Œå»ºæ§‹é€™å€‹è¤‡é›œçš„ prompt ï¼Œé™¤äº†æˆ‘å€‘æä¾›çš„æ–‡ä»¶å…§å®¹ (document content) çš„èªªæ˜ `document_content_description` å’Œè©®é‡‹è³‡æ–™ (metadata) çš„èªªæ˜ `metadata_field_info`ï¼ŒLangchain è‡ªå‹•æä¾›äº†ç¯„ä¾‹å’Œèƒ½é…åˆ vector store çš„é‹ç®—å­ (operators) çš„è³‡è¨Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to structure the user's query to match the request schema provided below.\n",
      "\n",
      "<< Structured Request Schema >>\n",
      "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"query\": string \\ text string to compare to document contents\n",
      "    \"filter\": string \\ logical condition statement for filtering documents\n",
      "}\n",
      "```\n",
      "\n",
      "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
      "\n",
      "A logical condition statement is composed of one or more comparison and logical operation statements.\n",
      "\n",
      "A comparison statement takes the form: `comp(attr, val)`:\n",
      "- `comp` (and | or): comparator\n",
      "- `attr` (string):  name of attribute to apply the comparison to\n",
      "- `val` (string): is the comparison value\n",
      "\n",
      "A logical operation statement takes the form `op(statement1, statement2, ...)`:\n",
      "- `op` (and | or): logical operator\n",
      "- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\n",
      "\n",
      "Make sure that you only use the comparators and logical operators listed above and no others.\n",
      "Make sure that filters only refer to attributes that exist in the data source.\n",
      "Make sure that filters only use the attributed names with its function names if there are functions applied on them.\n",
      "Make sure that filters only use format `YYYY-MM-DD` when handling timestamp data typed values.\n",
      "Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\n",
      "Make sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\n",
      "\n",
      "<< Example 1. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Lyrics of a song\",\n",
      "    \"attributes\": {\n",
      "        \"artist\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        },\n",
      "        \"length\": {\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"Length of the song in seconds\"\n",
      "        },\n",
      "        \"genre\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"teenager love\",\n",
      "    \"filter\": \"and(or(eq(\\\"artist\\\", \\\"Taylor Swift\\\"), eq(\\\"artist\\\", \\\"Katy Perry\\\")), lt(\\\"length\\\", 180), eq(\\\"genre\\\", \\\"pop\\\"))\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 2. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Lyrics of a song\",\n",
      "    \"attributes\": {\n",
      "        \"artist\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        },\n",
      "        \"length\": {\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"Length of the song in seconds\"\n",
      "        },\n",
      "        \"genre\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs that were not published on Spotify\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\n",
      "    \"query\": \"\",\n",
      "    \"filter\": \"NO_FILTER\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "<< Example 3. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"content\": \"Brief summary of a movie\",\n",
      "    \"attributes\": {\n",
      "    \"genre\": {\n",
      "        \"description\": \"The genre of the movie\",\n",
      "        \"type\": \"string or list[string]\"\n",
      "    },\n",
      "    \"year\": {\n",
      "        \"description\": \"The year the movie was released\",\n",
      "        \"type\": \"integer\"\n",
      "    },\n",
      "    \"director\": {\n",
      "        \"description\": \"The name of the movie director\",\n",
      "        \"type\": \"string\"\n",
      "    },\n",
      "    \"rating\": {\n",
      "        \"description\": \"A 1-10 rating for the movie\",\n",
      "        \"type\": \"float\"\n",
      "    }\n",
      "}\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\n",
      "\n",
      "Structured Request:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = load_query_constructor_chain(\n",
    "    llm=llm,\n",
    "    document_contents=document_content_description,\n",
    "    attribute_info=metadata_field_info,\n",
    "    # ä¾‹å­æ˜¯ Langchain é å…ˆæä¾›çš„\n",
    "    examples=DEFAULT_EXAMPLES,\n",
    "    # ä½¿ç”¨æ‰€é¸æ“‡çš„ vectoreDB æ‰€æ”¯æ´çš„ï¼Œè©®é‡‹è³‡æ–™ (metatdat) ç¯©é¸ (filter) ç”¨çš„é‹ç®—å­ (operators)\n",
    "    allowed_comparators=ChromaTranslator.allowed_operators,\n",
    "    allowed_operators=ChromaTranslator.allowed_operators,\n",
    ")\n",
    "print(chain.prompt.format(query=query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiVector\n",
    "æˆ‘å€‘æƒ³è¦å°‡æ–‡ä»¶ (document) çš„å…§å®¹å®Œæ•´åœ°å‚³çµ¦å¤§èªè¨€æ¨¡å‹ (LLM)ï¼Œä½†æ˜¯é€™å€‹æ–‡ä»¶å…§å®¹å› ç‚ºæŸäº›åŸå› ï¼ˆä¾‹å¦‚åŒ…å«çš„è³‡è¨Šå¤ªå¤šå¤ªé›œï¼‰è€Œä¸åˆ©æ–¼ embedding-based retrievalã€‚\n",
    "\n",
    "æˆ–æ˜¯ä¸æƒ³æ›´æ”¹æ–‡ä»¶æœ¬èº«å…§å®¹ï¼Œä½†åˆæƒ³æå‡æ–‡ä»¶æŠ½å– (document retrieval) çš„æº–åº¦çš„æ™‚å€™å¯ä»¥æ€éº¼è¾¦ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain å¯¦ä½œä¸¦ä»‹ç´¹äº†ä»¥ä¸‹ä¸‰ç¨®ä½œæ³•\n",
    "- åˆ†å¡Š (chunking)\n",
    "- æ‘˜è¦ (summarization): å°æ–‡ä»¶é€²è¡Œæ‘˜è¦ï¼Œä¸¦å°‡æ‘˜è¦çš„ embedding å’Œ/å–ä»£ æ–‡ä»¶çš„ embedding ä½œç‚ºè©²æ–‡ä»¶çš„å°æ‡‰\n",
    "- è™›æ“¬å‘½ä»¤/å•é¡Œ (hypothetical queries): ç”Ÿæˆé©åˆè©²æ–‡ä»¶å›ç­”çš„å•é¡Œï¼Œä¸¦å°‡è©²å•é¡Œçš„ embedding æˆ–è©²å•é¡ŒåŠ æ–‡ä»¶çš„ embedding ä½œç‚ºå°æ‡‰ã€‚\n",
    "\n",
    "é€™äº›ä½œæ³•çš„å…±é€šæ€ç¶­æ˜¯ï¼šé‡å°æºæ–‡ä»¶(source document)è¡ç”Ÿå‡ºèƒ½å¤ å°æ‡‰åˆ°è©²æ–‡ä»¶çš„æŸäº›è¡ç”Ÿç‰©(derivatives)ï¼Œè€Œé€™äº›è¡ç”Ÿç‰©æœƒå–ä»£æˆ–è·Ÿè‘—æºæ–‡ä»¶ä¸€èµ·æˆç‚ºæŠ½å–çš„å€™é¸ï¼Œè‹¥é¸åˆ°æŸå€‹è¡ç”Ÿç‰©ï¼Œå‰‡æœƒè¿½å¾ªå…¶å°æ‡‰æŠ½å–å‡ºå…¶å°æ‡‰çš„æ•´ä»½æºæ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "å¤ªé•·æˆ–å¤ªé›œçš„æ–‡ä»¶æœƒå°è‡´ç´°éƒ¨èªç¾©æœƒå½¼æ­¤ç¨€é‡‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "æŸå¤§å­¸çš„ç ”ç©¶å®¤ç™¼ç¾ï¼Œä¸–ç•Œä¸Šè‡³å°‘æœ‰16%éƒ¨æ‰‹æ©Ÿä¸Šæ˜¯æ²¾æœ‰ç³ä¾¿ç­‰æ’æ´©ç‰©çš„ã€‚\n",
      "\n",
      "åŸå­å¦‚æœæ²’æœ‰äº†ç©ºéš™çš„è©±ï¼Œé‚£éº¼å…¨ä¸–ç•Œçš„äººé¡å¯èƒ½æœƒè¢«æ“ å£“åˆ°è˜‹æœé‚£éº¼å¤§çš„ç©ºé–“ã€‚\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_setup import pprint_documents, pprint\n",
    "from langchain_setup.qdrant import pprint_qdrant_documents\n",
    "\n",
    "# æ–‡ä»¶\n",
    "doc = \"\"\"\\\n",
    "äººå£å¯†åº¦å¤§çš„åœ°éµé‡Œï¼Œç©ºæ°£ä¸­çš„è‡³å°‘æœ‰15%åŒ…å«è‘—æ¯å€‹äººçš„çš®è†šã€‚\n",
    "\n",
    "å…¶å¯¦è²“å’ªå…¶å¯¦ä¹Ÿå’Œäººé¡ä¸€æ¨£ï¼Œæ˜¯åˆ†å·¦æ’‡å­å’Œå³æ’‡å­çš„ï¼Œä¸éå…©è€…æ•¸é‡å·®ä¸å¤šï¼Œå¤§å®¶å¯ä»¥é—œæ³¨ä¸€ä¸‹èº«é‚Šçš„å–µæ˜Ÿäººï¼Œå¯èƒ½æœƒç™¼ç¾å®ƒå€‘ç¿’æ…£ç”¨å“ªä¸€éš»çˆªå­ï¼Œå°±çŸ¥é“å®ƒå€‘åˆ°åº•æ˜¯å·¦æ’‡å­é‚„æ˜¯å³æ’‡å­äº†ã€‚\n",
    "\n",
    "-----\n",
    "\n",
    "æŸå¤§å­¸çš„ç ”ç©¶å®¤ç™¼ç¾ï¼Œä¸–ç•Œä¸Šè‡³å°‘æœ‰16%éƒ¨æ‰‹æ©Ÿä¸Šæ˜¯æ²¾æœ‰ç³ä¾¿ç­‰æ’æ´©ç‰©çš„ã€‚\n",
    "\n",
    "åŸå­å¦‚æœæ²’æœ‰äº†ç©ºéš™çš„è©±ï¼Œé‚£éº¼å…¨ä¸–ç•Œçš„äººé¡å¯èƒ½æœƒè¢«æ“ å£“åˆ°è˜‹æœé‚£éº¼å¤§çš„ç©ºé–“ã€‚\n",
    "\"\"\"\n",
    "documents = [Document(page_content=doc)]\n",
    "\n",
    "# åˆ‡å‰²æ–‡ä»¶ (document splitting)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=0, separators=[\"-----\"], keep_separator=False\n",
    ")\n",
    "_documents = splitter.split_documents(documents)\n",
    "\n",
    "# å»ºç«‹ retriever\n",
    "retriever = Qdrant.from_documents(\n",
    "    _documents, OpenAIEmbeddings(), location=\":memory:\"\n",
    ").as_retriever(search_kwargs={\"k\": 1})\n",
    "pprint_documents(retriever.get_relevant_documents(\"è²“å’ªè¢«æ“ å£“åˆ°è˜‹æœå¤§çš„ç©ºé–“æ™‚æœƒç”¨å“ªéš»æ‰‹æ¸…ç†ç³ä¾¿ç­‰æ’æ³„ç‰©ï¼Ÿ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ‡åˆ†æ–‡ä»¶ (parent document) ä¸¦è®“å„åˆ‡åˆ† (child document) çš„ embedding ä¹Ÿéƒ½å°æ‡‰åˆ°è©²æ–‡ä»¶ (parent document)ã€‚\n",
    "\n",
    "ä½¿å¾—æ–‡ä»¶èƒ½å¤ å°æ‡‰åˆ°æ›´ç´°éƒ¨çš„èªç¾©ï¼Œä½†åŒæ™‚åˆèƒ½å¤ å°æ‡‰åˆ°æ•´ä»½æ–‡ä»¶è€Œééƒ¨åˆ†æ–‡ä»¶çµ¦ä¸‹ä¸€æ­¥é©Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "äººå£å¯†åº¦å¤§çš„åœ°éµé‡Œï¼Œç©ºæ°£ä¸­çš„è‡³å°‘æœ‰15%åŒ…å«è‘—æ¯å€‹äººçš„çš®è†šã€‚\n",
      "\n",
      "å…¶å¯¦è²“å’ªå…¶å¯¦ä¹Ÿå’Œäººé¡ä¸€æ¨£ï¼Œæ˜¯åˆ†å·¦æ’‡å­å’Œå³æ’‡å­çš„ï¼Œä¸éå…©è€…æ•¸é‡å·®ä¸å¤šï¼Œå¤§å®¶å¯ä»¥é—œæ³¨ä¸€ä¸‹èº«é‚Šçš„å–µæ˜Ÿäººï¼Œå¯èƒ½æœƒç™¼ç¾å®ƒå€‘ç¿’æ…£ç”¨å“ªä¸€éš»çˆªå­ï¼Œå°±çŸ¥é“å®ƒå€‘åˆ°åº•æ˜¯å·¦æ’‡å­é‚„æ˜¯å³æ’‡å­äº†ã€‚\n",
      "\n",
      "\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "# è¦ªåˆ†å‰²å™¨ (parent splitter) è² è²¬å¾åŸç”Ÿæ–‡ä»¶ (raw documents) åˆ‡å‡ºè¦ªæ–‡ä»¶ (parent documents)\n",
    "# parent documents æ˜¯æˆ‘å€‘è¦å‚³çµ¦å¤§èªè¨€æ¨¡å‹ (LLM) çš„\n",
    "# parent splitter æœ€é‡è¦çš„ä»»å‹™ä¹‹ä¸€æ˜¯ç¬¦åˆå¤§èªè¨€æ¨¡å‹çš„å¯è™•ç†é•·åº¦æˆ–å¯æœ‰æ•ˆè™•ç†çš„é•·åº¦\n",
    "parent_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=0, separators=[\"-----\"], keep_separator=False\n",
    ")\n",
    "\n",
    "# å­åˆ†å‰²å™¨ (child splitter) è² è²¬å†å¾æ¯å€‹è¦ªæ–‡ä»¶ä¸­å„è‡ªåˆ‡å‡ºæ›´å°çš„å­æ–‡ä»¶ (child documents)\n",
    "# å­åˆ†å‰²å™¨çš„ä»»å‹™æ˜¯è¦åˆ‡å‡ºé©åˆ embedding-based retrieval çš„ç‰‡æ®µ\n",
    "# é€šå¸¸æœƒå¸Œæœ›è©²ç‰‡æ®µå…§åŒè³ªæ€§é«˜å°‘é›œè¨Šæˆ–ä¸æœƒå¤ªé•·\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50, chunk_overlap=0, separators=[\"\\n\\n\"], keep_separator=False\n",
    ")\n",
    "\n",
    "# Empty Vectore store\n",
    "vectorstore = Qdrant.from_texts(\n",
    "    [\"dummy\"], embedding=OpenAIEmbeddings(), location=\":memory:\"\n",
    ")  #\n",
    "vectorstore.delete(\n",
    "    [vectorstore.client.scroll(vectorstore.collection_name)[0][0].id]\n",
    ")  # delete dummy\n",
    "\n",
    "# ParentDocumentRetriever\n",
    "chunk_retriever = ParentDocumentRetriever(\n",
    "    # vectore æœƒæ‹¿ä¾†å„²å­˜å­æ–‡ä»¶å’Œå…¶ embeddings\n",
    "    vectorstore=vectorstore,\n",
    "    # docstore æœƒå„²å­˜è¦ªæ–‡ä»¶\n",
    "    docstore=InMemoryStore(),\n",
    "    # æŠŠ splitter çµ¦ retriever è®“ retriever åœ¨æ–°å¢æ–‡ä»¶æ™‚å¹«å¿™åˆ‡\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,  # ä¸çµ¦ä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œæœƒç›´æ¥æŠŠå‚³å…¥çš„æ–‡ä»¶ (documents) åšç‚ºè¦ªæ–‡ä»¶ (parent documents)\n",
    "    # åªå–æœ€ç›¸é—œçš„ä¸€å€‹æ–‡ä»¶\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "# å¯¦éš›çœ‹çœ‹é€™æ¨£ç´°åˆ†çš„æ–¹æ³•èƒ½ä¸èƒ½å¹«åŠ©æˆ‘å€‘æŠ½å–åˆ°æ­£ç¢ºç›¸é—œçš„æ–‡ä»¶\n",
    "chunk_retriever.add_documents(\n",
    "    documents\n",
    ")  # æŠŠåŸç”Ÿæ–‡ä»¶ (raw documents) ä¸Ÿé€²å»çµ¦ `ParentDocumentRetriever` åˆ‡åˆ†å’Œè™•ç†\n",
    "retrieved_documents = chunk_retriever.get_relevant_documents(\"è²“å’ªè¢«æ“ å£“åˆ°è˜‹æœå¤§çš„ç©ºé–“æ™‚æœƒç”¨å“ªéš»æ‰‹æ¸…ç†ç³ä¾¿ç­‰æ’æ³„ç‰©ï¼Ÿ\")\n",
    "pprint_documents(retrieved_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘å€‘å¯ä»¥çœ‹åˆ° vectorstore å„²å­˜äº†å­æ–‡ä»¶ (child document) å°æ‡‰çš„è¦ªæ–‡ä»¶ (parent document) çš„è­˜åˆ¥ç¢¼ (id)\n",
    "\n",
    "è€Œ docstore å‰‡å„²å­˜è¦ªæ–‡ä»¶ (parent documents) å’Œå…¶è­˜åˆ¥ç¢¼ (ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR STORE\n",
      "\n",
      "Document 63d5171a5e8e4d2db8f93ab8b36a9bdf:\n",
      "\n",
      "åŸå­å¦‚æœæ²’æœ‰äº†ç©ºéš™çš„è©±ï¼Œé‚£éº¼å…¨ä¸–ç•Œçš„äººé¡å¯èƒ½æœƒè¢«æ“ å£“åˆ°è˜‹æœé‚£éº¼å¤§çš„ç©ºé–“ã€‚\n",
      "\n",
      "Metadata:{'doc_id': 'f63569e1-a7a8-40ad-aaac-fe3116edce4b'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6849b0c9f22f421dbe8f1483bc3298a6:\n",
      "\n",
      "æŸå¤§å­¸çš„ç ”ç©¶å®¤ç™¼ç¾ï¼Œä¸–ç•Œä¸Šè‡³å°‘æœ‰16%éƒ¨æ‰‹æ©Ÿä¸Šæ˜¯æ²¾æœ‰ç³ä¾¿ç­‰æ’æ´©ç‰©çš„ã€‚\n",
      "\n",
      "Metadata:{'doc_id': 'f63569e1-a7a8-40ad-aaac-fe3116edce4b'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7424ec0f04f146dba2edc81f6e81edc7:\n",
      "\n",
      "äººå£å¯†åº¦å¤§çš„åœ°éµé‡Œï¼Œç©ºæ°£ä¸­çš„è‡³å°‘æœ‰15%åŒ…å«è‘—æ¯å€‹äººçš„çš®è†šã€‚\n",
      "\n",
      "Metadata:{'doc_id': '95c8b6fb-5154-46f8-8138-5c9fdb777b6b'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document bc112bc738204db4a62b49adea73ee50:\n",
      "\n",
      "å…¶å¯¦è²“å’ªå…¶å¯¦ä¹Ÿå’Œäººé¡ä¸€æ¨£ï¼Œæ˜¯åˆ†å·¦æ’‡å­å’Œå³æ’‡å­çš„ï¼Œä¸éå…©è€…æ•¸é‡å·®ä¸å¤šï¼Œå¤§å®¶å¯ä»¥é—œæ³¨ä¸€ä¸‹èº«é‚Šçš„å–µæ˜Ÿäººï¼Œå¯èƒ½æœƒç™¼ç¾å®ƒå€‘ç¿’æ…£ç”¨å“ªä¸€éš»çˆªå­ï¼Œå°±çŸ¥é“å®ƒå€‘åˆ°åº•æ˜¯å·¦æ’‡å­é‚„æ˜¯å³æ’‡å­äº†ã€‚\n",
      "\n",
      "Metadata:{'doc_id': '95c8b6fb-5154-46f8-8138-5c9fdb777b6b'}\n",
      "DOCSTORE\n",
      "\n",
      "{'store': {'95c8b6fb-5154-46f8-8138-5c9fdb777b6b': Document(page_content='äººå£å¯†åº¦å¤§çš„åœ°éµé‡Œï¼Œç©ºæ°£ä¸­çš„è‡³å°‘æœ‰15%åŒ…å«è‘—æ¯å€‹äººçš„çš®è†šã€‚\\n\\nå…¶å¯¦è²“å’ªå…¶å¯¦ä¹Ÿå’Œäººé¡ä¸€æ¨£ï¼Œæ˜¯åˆ†å·¦æ’‡å­å’Œå³æ’‡å­çš„ï¼Œä¸éå…©è€…æ•¸é‡å·®ä¸å¤šï¼Œå¤§å®¶å¯ä»¥é—œæ³¨ä¸€ä¸‹èº«é‚Šçš„å–µæ˜Ÿäººï¼Œå¯èƒ½æœƒç™¼ç¾å®ƒå€‘ç¿’æ…£ç”¨å“ªä¸€éš»çˆªå­ï¼Œå°±çŸ¥é“å®ƒå€‘åˆ°åº•æ˜¯å·¦æ’‡å­é‚„æ˜¯å³æ’‡å­äº†ã€‚\\n\\n'),\n",
      "           'f63569e1-a7a8-40ad-aaac-fe3116edce4b': Document(page_content='æŸå¤§å­¸çš„ç ”ç©¶å®¤ç™¼ç¾ï¼Œä¸–ç•Œä¸Šè‡³å°‘æœ‰16%éƒ¨æ‰‹æ©Ÿä¸Šæ˜¯æ²¾æœ‰ç³ä¾¿ç­‰æ’æ´©ç‰©çš„ã€‚\\n\\nåŸå­å¦‚æœæ²’æœ‰äº†ç©ºéš™çš„è©±ï¼Œé‚£éº¼å…¨ä¸–ç•Œçš„äººé¡å¯èƒ½æœƒè¢«æ“ å£“åˆ°è˜‹æœé‚£éº¼å¤§çš„ç©ºé–“ã€‚')}}\n"
     ]
    }
   ],
   "source": [
    "print(\"VECTOR STORE\", end=\"\\n\\n\")\n",
    "pprint_qdrant_documents(vectorstore)\n",
    "print(\"DOCSTORE\", end=\"\\n\\n\")\n",
    "pprint(chunk_retriever.docstore.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "ç•¶æ–‡ç« æœ¬èº«éå¸¸é•·æˆ–è³‡è¨Šéå¸¸é›œï¼Œembedding æœƒé›œè³ªå¾ˆå¤šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain_setup import ChatOpenAI, pprint_documents\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"æ¯”é»‘è‰²æ›´é»‘ï¼Œæ¯”é»‘æš—æ›´æš—çš„æ¼†é»‘ï¼Œåœ¨æ­¤å¯„è¨—å¾çœŸç´…çš„é‡‘å…‰å§ï¼è¦ºé†’ä¹‹æ™‚çš„åˆ°ä¾†ï¼Œè’è¬¬è‡³æ¥µçš„å¢®è½ç« ç†ï¼Œæˆç‚ºç„¡å½¢çš„æ‰­æ›²è€Œé¡¯ç¾å§ï¼èµ·èˆå§ï¼Œèµ·èˆå§ï¼Œèµ·èˆå§ï¼å¾ä¹‹åŠ›é‡æœ¬æºä¹‹æ„¿çš„å´©å£ï¼Œç„¡äººå¯åŠçš„å´©å£ï¼Œå°‡å¤©åœ°è¬è±¡ç„šç‡’æ®†ç›¡ï¼Œè‡ªæ·±æ·µé™è‡¨å§ï¼Œé€™å°±æ˜¯äººé¡æœ€å¼·å¨åŠ›çš„æ”»æ“Šæ‰‹æ®µï¼Œé€™å°±æ˜¯ç©¶æ¥µæ”»æ“Šé­”æ³•ï¼ŒExplosion!\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘å€‘å¯ä»¥é€éé‡é»æ•´ç†ä¾†ç²¾ç…‰ embeddingï¼Œä½¿ embedding-based retrieval æ›´æº–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "æ¯”é»‘è‰²æ›´é»‘ï¼Œæ¯”é»‘æš—æ›´æš—çš„æ¼†é»‘ï¼Œåœ¨æ­¤å¯„è¨—å¾çœŸç´…çš„é‡‘å…‰å§ï¼è¦ºé†’ä¹‹æ™‚çš„åˆ°ä¾†ï¼Œè’è¬¬è‡³æ¥µçš„å¢®è½ç« ç†ï¼Œæˆç‚ºç„¡å½¢çš„æ‰­æ›²è€Œé¡¯ç¾å§ï¼èµ·èˆå§ï¼Œèµ·èˆå§ï¼Œèµ·èˆå§ï¼å¾ä¹‹åŠ›é‡æœ¬æºä¹‹æ„¿çš„å´©å£ï¼Œç„¡äººå¯åŠçš„å´©å£ï¼Œå°‡å¤©åœ°è¬è±¡ç„šç‡’æ®†ç›¡ï¼Œè‡ªæ·±æ·µé™è‡¨å§ï¼Œé€™å°±æ˜¯äººé¡æœ€å¼·å¨åŠ›çš„æ”»æ“Šæ‰‹æ®µï¼Œé€™å°±æ˜¯ç©¶æ¥µæ”»æ“Šé­”æ³•ï¼ŒExplosion!\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "# å¾æºæ–‡ä»¶ (source documents) ç”¢ç”Ÿè¡ç”Ÿç‰© (derivatives)\n",
    "chain = (\n",
    "    {\"doc\": attrgetter(\"page_content\")}\n",
    "    | ChatPromptTemplate.from_template(\"è«‹ç”¨ä¸€å¥è©±æ‘˜è¦ä¸‹åˆ—çš„è³‡è¨Š:\\n\\n{doc}\")\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "summaries = chain.batch(documents)  # å¹³è¡ŒåŒ–è™•ç†\n",
    "\n",
    "# æ¨™æ³¨æºæ–‡ä»¶å’Œè¡ç”Ÿç‰©çš„å°æ‡‰\n",
    "child_documents = []\n",
    "document_ids = []\n",
    "for i, (summary, document) in enumerate(zip(summaries, documents)):\n",
    "    document_id = str(i)\n",
    "    child_document = Document(page_content=summary, metadata={\"doc_id\": document_id})\n",
    "    child_documents.append(child_document)\n",
    "    document_ids.append(document_id)\n",
    "\n",
    "# è¡ç”Ÿç‰©å­˜å…¥ vectorestore\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=child_documents, embedding=OpenAIEmbeddings(), location=\":memory:\"\n",
    ")\n",
    "\n",
    "# [Optional] å°‡æºæ–‡ä»¶ä¹Ÿå­˜å…¥ vectorstore\n",
    "_documents = []\n",
    "for document_id, document in zip(document_ids, documents):\n",
    "    _document = Document(\n",
    "        page_content=document.page_content, metadata={\"doc_id\": document_id}\n",
    "    )\n",
    "    _documents.append(_document)\n",
    "vectorstore.add_documents(documents=_documents)\n",
    "\n",
    "# å„²å­˜æºæ–‡ä»¶ (source documents) åŠå…¶è­˜åˆ¥ (id)\n",
    "docstore = InMemoryStore()\n",
    "docstore.mset(list(zip(document_ids, documents)))\n",
    "\n",
    "# å»ºç«‹ MultiVectorRetriever\n",
    "summary_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=\"doc_id\",\n",
    ")\n",
    "\n",
    "# è©¦è‘—æŠ½å–çœ‹çœ‹\n",
    "retrieved_docs = summary_retriever.get_relevant_documents(\"ä»€éº¼é­”æ³•æœƒå°‡ä¸€åˆ‡ç‡ƒç‡’æ®†ç›¡ï¼Ÿ\")\n",
    "pprint_documents(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å…¶å¯¦çœŸæ­£é€é embedding-based retrieval é¸åˆ°çš„æ˜¯å…¶è¡ç”Ÿç‰©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ä½¿ç”¨æœ€å¼·çš„æ”»æ“Šé­”æ³•\"Explosion\"ï¼Œå°‡ä¸€åˆ‡ç‡ƒç‡’æ®†ç›¡ã€‚', metadata={'doc_id': '0'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_retriever.vectorstore.similarity_search(query=\"ä»€éº¼é­”æ³•æœƒå°‡ä¸€åˆ‡ç„šç‡’æ®†ç›¡ï¼Ÿ\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothetical Queries\n",
    "ç•¶æˆ‘å€‘åœ¨æ‰¾è³‡æ–™æ™‚æœƒçœ‹æœ‰æ²’æœ‰å…¶ä»–äººå•éé¡ä¼¼çš„å•é¡Œï¼Œè€Œåœ¨æ–‡ä»¶æŠ½å–ï¼ˆdocument retrievalï¼‰ä¸­æˆ‘å€‘ä¹Ÿå¯ä»¥å¯¦è¸é€™å€‹æ€è·¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain.chains.openai_functions.base import convert_to_openai_function\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_setup import ChatOpenAI, pprint_documents\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"æ¯”é»‘è‰²æ›´é»‘ï¼Œæ¯”é»‘æš—æ›´æš—çš„æ¼†é»‘ï¼Œåœ¨æ­¤å¯„è¨—å¾çœŸç´…çš„é‡‘å…‰å§ï¼è¦ºé†’ä¹‹æ™‚çš„åˆ°ä¾†ï¼Œè’è¬¬è‡³æ¥µçš„å¢®è½ç« ç†ï¼Œæˆç‚ºç„¡å½¢çš„æ‰­æ›²è€Œé¡¯ç¾å§ï¼èµ·èˆå§ï¼Œèµ·èˆå§ï¼Œèµ·èˆå§ï¼å¾ä¹‹åŠ›é‡æœ¬æºä¹‹æ„¿çš„å´©å£ï¼Œç„¡äººå¯åŠçš„å´©å£ï¼Œå°‡å¤©åœ°è¬è±¡ç„šç‡’æ®†ç›¡ï¼Œè‡ªæ·±æ·µé™è‡¨å§ï¼Œé€™å°±æ˜¯äººé¡æœ€å¼·å¨åŠ›çš„æ”»æ“Šæ‰‹æ®µï¼Œé€™å°±æ˜¯ç©¶æ¥µæ”»æ“Šé­”æ³•ï¼ŒExplosion!\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘å€‘è®“å¤§èªè¨€æ¨¡å‹ (LLM) æ ¹æ“šæ–‡ä»¶ (document) å…§å®¹è‡ªå‹•ç”¢ç”Ÿå•å¥ (queries)ï¼Œä»¥é€™äº›å•å¥ä½œç‚ºè©²æ–‡ä»¶çš„è¡ç”Ÿç‰© (derivatives)ï¼ŒæŠ½å–åˆ°é€™äº›å•é¡Œå°±å›å‚³å…¶å°æ‡‰çš„æºæ–‡ä»¶ (source document)ã€‚é€™å€‹æ–¹æ³•æœ‰å¹¾å€‹å¥½è™•\n",
    "1. æ¯å€‹å•é¡Œå¯èƒ½å¯ä»¥ä»£è¡¨å…§å®¹ä¸åŒçš„é¢å‘æˆ–æªè¾­\n",
    "2. é™¤äº†è‡ªå‹•ç”¢ç”Ÿçš„å•é¡Œå¤–ï¼Œä¹Ÿå¯ä»¥æ‰‹å‹•å°‡å¤±æ•—çš„å•é¡Œ (query) å°æ‡‰åˆ°æ­£ç¢ºçš„æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='æ¯”é»‘è‰²æ›´é»‘ï¼Œæ¯”é»‘æš—æ›´æš—çš„æ¼†é»‘ï¼Œåœ¨æ­¤å¯„è¨—å¾çœŸç´…çš„é‡‘å…‰å§ï¼è¦ºé†’ä¹‹æ™‚çš„åˆ°ä¾†ï¼Œè’è¬¬è‡³æ¥µçš„å¢®è½ç« ç†ï¼Œæˆç‚ºç„¡å½¢çš„æ‰­æ›²è€Œé¡¯ç¾å§ï¼èµ·èˆå§ï¼Œèµ·èˆå§ï¼Œèµ·èˆå§ï¼å¾ä¹‹åŠ›é‡æœ¬æºä¹‹æ„¿çš„å´©å£ï¼Œç„¡äººå¯åŠçš„å´©å£ï¼Œå°‡å¤©åœ°è¬è±¡ç„šç‡’æ®†ç›¡ï¼Œè‡ªæ·±æ·µé™è‡¨å§ï¼Œé€™å°±æ˜¯äººé¡æœ€å¼·å¨åŠ›çš„æ”»æ“Šæ‰‹æ®µï¼Œé€™å°±æ˜¯ç©¶æ¥µæ”»æ“Šé­”æ³•ï¼ŒExplosion!')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¾æºæ–‡ä»¶ (source documents) ç”¢ç”Ÿè¡ç”Ÿç‰© (derivatives)\n",
    "class hypothetical_questions(BaseModel):\n",
    "    \"\"\"Generate hypothetical questions\"\"\"\n",
    "\n",
    "    questions: list[str]\n",
    "\n",
    "\n",
    "function = convert_to_openai_function(hypothetical_questions)\n",
    "\n",
    "query_gen_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"è«‹ç”¢ç”Ÿä¸‰å€‹å¯ä»¥æ ¹æ“šä»¥ä¸‹çš„è³‡è¨Šå›ç­”çš„å•é¡Œ:\\n\\n{doc}\")  # å¯ä»¥è¨­å®šæ›´å¤šå€‹\n",
    "    # åœ¨é€™é‚Šç‚ºäº†æ•™å­¸å°‡æº«åº¦ (temperature) è¨­ç‚ºé›¶ï¼Œä½†å¯¦éš›ä¸Šå¢åŠ ä¸€äº›éš¨æ©Ÿæ€§æœƒæ¯”è¼ƒå¥½\n",
    "    | ChatOpenAI(temperature=0).bind(\n",
    "        functions=[function], function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")\n",
    "questions = query_gen_chain.batch(documents)\n",
    "\n",
    "# æ¨™æ³¨æºæ–‡ä»¶å’Œè¡ç”Ÿç‰©çš„å°æ‡‰\n",
    "child_documents = []\n",
    "document_ids = []\n",
    "for i, (_questions, document) in enumerate(zip(questions, documents)):\n",
    "    document_id = str(i)\n",
    "    for question in _questions:\n",
    "        child_document = Document(\n",
    "            page_content=question, metadata={\"doc_id\": document_id}\n",
    "        )\n",
    "        child_documents.append(child_document)\n",
    "    document_ids.append(document_id)\n",
    "\n",
    "# è¡ç”Ÿç‰©å­˜å…¥ vectorestore\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=child_documents, embedding=OpenAIEmbeddings(), location=\":memory:\"\n",
    ")\n",
    "\n",
    "# [Optional] å°‡æºæ–‡ä»¶ä¹Ÿå­˜å…¥ vectorstore\n",
    "_documents = []\n",
    "for document_id, document in zip(document_ids, documents):\n",
    "    _document = Document(\n",
    "        page_content=document.page_content, metadata={\"doc_id\": document_id}\n",
    "    )\n",
    "    _documents.append(_document)\n",
    "vectorstore.add_documents(documents=_documents)\n",
    "\n",
    "# å„²å­˜æºæ–‡ä»¶ (source documents) åŠå…¶è­˜åˆ¥ (id)\n",
    "docstore = store = InMemoryStore()\n",
    "docstore.mset(list(zip(document_ids, documents)))\n",
    "\n",
    "# å»ºç«‹ MultiVectorRetriever\n",
    "hypothetical_questions_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=\"doc_id\",\n",
    ")\n",
    "\n",
    "# è©¦è‘—æŠ½å–çœ‹çœ‹\n",
    "hypothetical_questions_retriever.get_relevant_documents(\"ä»€éº¼é­”æ³•æ˜¯äººé¡æœ€å¼·çš„æ”»æ“Šï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å…¶å¯¦çœŸæ­£é€é embedding-based retrieval é¸åˆ°çš„æ˜¯å…¶è¡ç”Ÿç‰©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ä»€éº¼é¡è‰²æ¯”é»‘è‰²æ›´é»‘ï¼Ÿ', 'ä»€éº¼æ¯”é»‘æš—æ›´æš—ï¼Ÿ', 'ä»€éº¼æ˜¯äººé¡æœ€å¼·å¨åŠ›çš„æ”»æ“Šæ‰‹æ®µï¼Ÿ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ä»€éº¼æ˜¯äººé¡æœ€å¼·å¨åŠ›çš„æ”»æ“Šæ‰‹æ®µï¼Ÿ', metadata={'doc_id': '0'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(questions)\n",
    "\n",
    "hypothetical_questions_retriever.vectorstore.similarity_search(\n",
    "    query=\"ä»€éº¼é­”æ³•æ˜¯äººé¡æœ€å¼·çš„æ”»æ“Šï¼Ÿ\", k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æƒ³æƒ³çœ‹**: MultiQuery æ˜¯å¾ä½¿ç”¨è€…å•å¥ (user query)ï¼Œæ”¹å¯«æˆå¤šå€‹å•å¥ã€‚Hypothetical queries å‰‡æ˜¯å¾æ–‡ä»¶å‡ºç™¼ï¼Œè¨­è¨ˆä¸åŒçš„å•å¥ã€‚é€™å…©å€‹æ–¹æ³•é–“åœ¨èƒ½é”æˆçš„æ•ˆæœä¸Šæœ‰ä½•ä¸åŒï¼Ÿä»€éº¼æƒ…æ³ä¸‹ç”¨å“ªå€‹æ¯”è¼ƒå¥½ï¼Ÿå¯ä»¥åˆä½µä¸€èµ·ç”¨å—ï¼Ÿ\n",
    "<details>\n",
    "<summary>åƒè€ƒ</summary>\n",
    "ç•¶ä½¿ç”¨è€…å•å¥éå¸¸è¤‡é›œä¸”éš±å«è¤‡æ•¸æ¢ä»¶æˆ–è¦æ±‚æ™‚ï¼Œå¯ä»¥åˆ©ç”¨MultiQuery å°‡å…¶æ‹†è§£æˆæ•¸å€‹æ¯”è¼ƒå–®ç´”çš„ queryã€‚hypothetical queries å‰‡å¯ä»¥ç•¶ä½œæ˜¯æŸç¨®æ‹†è§£è¤‡é›œæ–‡ä»¶è³‡è¨Šæˆä¸åŒçš„å–®ç´”é¢å‘çš„æ–¹æ³•ã€‚å¦å¤–å€‹äººèªç‚ºå…©ç¨®æ–¹æ³•éƒ½å¯ä»¥é”åˆ°æ¸›å°‘å› ç‚ºæªè¾­å·®ç•°è€Œå°æ‡‰ä¸åˆ°çš„å•é¡Œã€‚å…©è€…å…¶å¯¦ä¸æ˜¯åªèƒ½ä½¿ç”¨ä¸€ç¨®ï¼Œåˆä½µä½¿ç”¨æ˜¯å¯èƒ½çš„ã€‚\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeWeightedVectorStoreRetriever\n",
    "\n",
    "`recency_score = semantic_similarity + (1.0 - decay_rate) ^ hours_passed_since_last_access`\n",
    "- è·Ÿä½•æ™‚å‰µå»ºçš„æª”æ¡ˆç„¡é—œï¼Œå°±ç®—æ˜¯å¾ˆä»¥å‰çš„æª”æ¡ˆï¼Œåªè¦æœ€è¿‘æœ‰è¢«æŠ½å–åˆ°ï¼Œå°±æ˜¯æ–°é®®çš„\n",
    "- æœƒçµ¦æ¯å€‹æ–‡ä»¶è‡ªå‹•æ¨™è¨»ä¸Š\n",
    "  - `last_accessed_at` (æœ€å¾Œå­˜å–æ™‚é–“): ç”¨æ–¼è¨ˆç®—ç¶“éçš„æ™‚é–“\n",
    "  - `created_at` (å‰µå»ºæ™‚é–“): æ²’æœ‰è¢«ç”¨åˆ°ï¼Œå¯èƒ½åªæ˜¯è®“ä½ åƒè€ƒç”¨\n",
    "- `decay_rate` è¶Šå¤§ï¼Œè¶Šä¹…æ²’è¢«ç¢°çš„æ–‡ä»¶è¶Šä¸å®¹æ˜“è¢«ç¢°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 08f4b87f627d43c6b6cc80a175712efd:\n",
      "\n",
      "æ˜¨å¤©çš„é¢¨å…’çœŸæ˜¯å–§å›‚å‘¢\n",
      "\n",
      "Metadata:\n",
      "{'buffer_idx': 0,\n",
      " 'created_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 66934),\n",
      " 'last_accessed_at': datetime.datetime(2023, 11, 9, 18, 1, 27, 66934)}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6cc62d526e26428ab1ce29edf074fc4f:\n",
      "\n",
      "é€™å€‹å‘³é“æ˜¯èªªè¬Šçš„å‘³é“\n",
      "\n",
      "Metadata:\n",
      "{'buffer_idx': 1,\n",
      " 'created_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 313571),\n",
      " 'last_accessed_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 313571)}\n",
      "\n",
      "=========== æŠ½å– (retrieval) çµæœ ===========\n",
      "\n",
      "Document 1:\n",
      "\n",
      "é€™å€‹å‘³é“æ˜¯èªªè¬Šçš„å‘³é“\n",
      "\n",
      "Metadata:\n",
      "{'buffer_idx': 1,\n",
      " 'created_at': datetime.datetime(2023, 11, 10, 18, 1, 27, 313571),\n",
      " 'last_accessed_at': datetime.datetime(2023, 11, 10, 18, 1, 28, 578207)}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_setup import pprint_documents\n",
    "from langchain_setup.qdrant import create_inmemory_empty_qdrant, pprint_qdrant_documents\n",
    "\n",
    "# ä»¥ç©ºçš„ vector store ä¾†å»ºç«‹ retriever\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=create_inmemory_empty_qdrant(), decay_rate=0.999, k=1\n",
    ")\n",
    "\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "# æœ€å¾Œå­˜å–æ™‚é–“ (last_accessed_at) å’Œ å‰µå»ºæ™‚é–“ (created_at) å¯ä»¥æ‰‹å‹•è¨­å®š\n",
    "retriever.add_documents(\n",
    "    [Document(page_content=\"æ˜¨å¤©çš„é¢¨å…’çœŸæ˜¯å–§å›‚å‘¢\", metadata={\"last_accessed_at\": yesterday})]\n",
    ")\n",
    "# æˆ–æ˜¯ä¸è¨­å®šçš„è©±å°±æ˜¯å…©å€‹çš†è¨­ç‚ºç¾åœ¨æ™‚é–“\n",
    "retriever.add_documents([Document(page_content=\"é€™å€‹å‘³é“æ˜¯èªªè¬Šçš„å‘³é“\")])\n",
    "\n",
    "# æª¢è¦– vector store å…§éƒ¨\n",
    "pprint_qdrant_documents(retriever.vectorstore)\n",
    "time.sleep(1)\n",
    "\n",
    "# ç”±æ–¼è¨­å®šæ¥µé«˜ decay rate ï¼ŒæŠ½å– (retrieve) åˆ°éå»å–ç”¨ (access) çš„æ–‡ä»¶çš„å¯èƒ½æ€§æ¥µä½\n",
    "# è¢«æŠ½å–çš„æ–‡ä»¶çš„æœ€å¾Œå­˜å–æ™‚é–“æœƒè‡ªå‹•æ›´æ–°\n",
    "print(\"\\n=========== æŠ½å– (retrieval) çµæœ ===========\\n\")\n",
    "pprint_documents(retriever.get_relevant_documents(\"é¢¨å…’å¾ˆå–§å›‚\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æƒ³æƒ³çœ‹:\n",
    "- è¶Šä¹…æ²’è¢«ç¢°çš„æ–‡ä»¶è¶Šè¢«é›£æŠ½å–ï¼Œåœ¨ä»€éº¼æ¨£çš„æƒ…æ³ä¸‹æœƒé€ æˆæƒ¡æ€§å¾ªç’°?\n",
    "- è¦æ€éº¼å¯¦ä½œç”¨ã€Œæª”æ¡ˆå‰µå»ºæ™‚é–“ã€æˆ–ã€Œæª”æ¡ˆå…§å®¹æ›´æ–°æ™‚é–“ã€ä¾†åš time decay ?\n",
    "\n",
    "<details>\n",
    "<summary>åƒè€ƒ</summary>\n",
    "æœ‰ç”¨ä½†æ˜¯å¾ˆå°‘è¢«ç”¨çš„æ–‡ä»¶ï¼Œå› å°‘è¢«æŠ½å–è€Œè¢«é™ä½é †åºï¼Œå› é™ä½é †ä½è€Œè¢«æ›´å°‘æŠ½å–\n",
    "\n",
    "å¯ä»¥å˜—è©¦æ‰‹å‹•å°‡æ–‡ä»¶ (Document) çš„ 'last_accessed_at' å€¼è¨­æˆæˆ‘å€‘æƒ³è¦çš„æ—¥æœŸæ™‚é–“\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Retriever\n",
    "åœ¨ä»‹ç´¹æŠ½å–å™¨ (Retriever) æ™‚æˆ‘å€‘æåˆ°äº†é™¤äº†åŸºæ–¼ embeddings ç›¸ä¼¼åº¦ä»¥å¤–çš„æŠ½å–å™¨ï¼Œè€Œæˆ‘å€‘å‰›æ‰ä¹Ÿä»‹ç´¹éäº†è¨±å¤šé€²éšçš„æŠ½å–å™¨ã€‚æ¯å€‹æŠ½å–å™¨éƒ½æœ‰ä¸åŒçš„ç‰¹æ€§ï¼Œæˆ‘å€‘æ˜¯å¦å¯ä»¥çµåˆä¸åŒçš„å„ªå‹¢ä¾†æˆªé•·è£œçŸ­ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸¦è¯\n",
    "å°‡å¾ä¸åŒç¨®é¡çš„æŠ½å–å™¨æ‰€å¾—åˆ°çš„ç›¸é—œæ€§åˆ†æ•¸ (relevance score) ä»¥ä½¿ç”¨è€…è¨­å®šçš„æ¬Šé‡ (weights) çµåˆï¼Œä½œç‚ºè©²æ–‡ä»¶ (document) çš„æœ€çµ‚ç›¸é—œæ€§åˆ†æ•¸ï¼Œä¸¦ä»¥è©²åˆ†æ•¸ä½œç‚ºæ ¹æ“šæŠ½å– (retrieve)ã€‚\n",
    "\n",
    "é€™ç¨®æ–¹æ³•é›–ç„¶æ¯”è¼ƒèŠ±æˆæœ¬ï¼Œä½†æ˜¯å¯èƒ½å¯ä»¥æé«˜å¬å›ç‡ (recall)ï¼Œä¹Ÿå°±æ˜¯æ¸›å°‘çœŸçš„ç›¸é—œçš„æ–‡ä»¶ (document) æ²’æœ‰è¢«æŠ½å–åˆ°çš„æ©Ÿç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Ugh! Pen Pineapple Apple Pen\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Apple pen~\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Pineapple pen~\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_setup import pprint_documents\n",
    "\n",
    "doc_list = [\n",
    "    \"Apple pen~\",\n",
    "    \"Pineapple pen~\",\n",
    "    \"Ugh! Pen Pineapple Apple Pen\",\n",
    "]\n",
    "\n",
    "# åŸºæ–¼èªé¢çš„æŠ½å– (Lexical-based retrieval) (BM25)\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "# åŸºæ–¼èªç¾© embedding çš„æŠ½å– (Embedding-based retrieval)\n",
    "vectorstore = Qdrant.from_texts(doc_list, OpenAIEmbeddings(), location=\":memory:\")\n",
    "embedding_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# çµ„åˆ (ensemble) å…©ç¨®æŠ½å–å™¨ (retriever)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, embedding_retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "docs = ensemble_retriever.get_relevant_documents(\"apples\")\n",
    "pprint_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸²é€£\n",
    "å¤šéšæ®µçš„ï¼ˆmulti-stagedï¼‰æ–¹æ³•åœ¨å»ºæ§‹æœå°‹ç³»çµ±ä¸­æ˜¯å¸¸è¢«ä½¿ç”¨åˆ°çš„æ–¹æ³•ã€‚å…¶æœƒå…ˆç”¨æ¯”è¼ƒå¼±ä½†æ¯”è¼ƒå¿«çš„æ’åº (ranking) æ–¹æ³•ï¼Œé…åˆæ¯”è¼ƒå¯¬é¬†çš„ç›¸é—œåº¦é–¥å€¼ (threshold) åšå¤§é‡ç¯©é¸ï¼Œå†åªæŠŠç²—ç¯©éå¾Œçš„çµæœå‚³çµ¦ä¸‹ä¸€å€‹æ›´å¼·ä½†æ›´æ…¢çš„æ’åº (ranking) æ–¹æ³•åšç¯©é¸æˆ–æ’åºï¼Œç„¶å¾Œå¯èƒ½å†é‡è¤‡å‚³çµ¦ä¸‹ä¸€å€‹æ›´å¼·æ’åºæ–¹æ³•çš„éç¨‹ã€‚\n",
    "\n",
    "ç•¶æ–‡æœ¬ (documents) æ•¸é‡å¾ˆå¤§æ™‚ï¼Œé€™æ˜¯ä¸€å€‹å¯ä»¥åŒæ™‚é¡§åŠæˆæœ¬ã€ç²¾æº–åº¦ (precision)ã€å¬å›ç‡ (recall) çš„æ–¹æ³•\n",
    "\n",
    "é›–ç„¶ Langchain æ²’æœ‰ä»‹ç´¹ä¸²é€£çš„ä½œæ³•æˆ–ç¾æˆçš„å¯¦ä½œï¼Œä½†æˆ‘å€‘é‚„æ˜¯å¯ä»¥é€éç¾æœ‰çš„æ±è¥¿æ‹¼æ¹Šå‡ºä¾†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\121664\\micromamba\\envs\\dev\\lib\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\121664\\micromamba\\envs\\dev\\lib\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\121664\\micromamba\\envs\\dev\\lib\\site-packages\\langchain\\chains\\llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Apple pen~\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Ugh! Pen Pineapple Apple Pen\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_setup import pprint_documents\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_setup import ChatOpenAI\n",
    "\n",
    "doc_list = [\n",
    "    \"å¤©ä¹‹é–\",\n",
    "    \"ä¿®çˆ¾å¤ä¼½é‚£\",\n",
    "    \"å¤©åœ°ä¹–é›¢é–‹é—¢ä¹‹æ˜Ÿ\",\n",
    "    \"ç‹ä¹‹è™Ÿç ²\",\n",
    "    \"é»‘å¸æ–¯çš„éš±å½¢é ­ç›”\",\n",
    "    \"Apple pen~\",\n",
    "    \"Pineapple pen~\",\n",
    "    \"Ugh! Pen Pineapple Apple Pen\",\n",
    "]\n",
    "\n",
    "# åŸºæ–¼èªç¾© embedding çš„æŠ½å– (Embedding-based retrieval) é…ä¸Šä¸€å€‹ç›¸å°å¯¬é¬†çš„ç¯©é¸é–¥å€¼ (threshold)\n",
    "vectorstore = Qdrant.from_texts(doc_list, OpenAIEmbeddings(), location=\":memory:\")\n",
    "embedding_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.75}\n",
    ")\n",
    "\n",
    "# ä»¥å¤§å‹èªè¨€æ¨¡å‹ (LLM) ä¾†ç›´æ¥åŒæ™‚æ¯”è¼ƒå…©ç¯‡æ–‡ç« çš„æ–¹æ³•\n",
    "stronger_ranking = LLMChainFilter.from_llm(ChatOpenAI(temperature=0))\n",
    "\n",
    "# ä¸²é€£\n",
    "cascade_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=embedding_retriever, base_compressor=stronger_ranking\n",
    ")\n",
    "\n",
    "docs = cascade_retriever.get_relevant_documents(\"apples\")\n",
    "pprint_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¾ä¸‹æ–¹ä¾‹å­å¯ä»¥çœ‹å‡ºï¼Œåœ¨ç¬¬ä¸€éšæ®µæ™‚ä¾¿å·²éæ¿¾æ‰æ˜é¡¯ä¸ç›¸é—œçš„æ–‡ä»¶ (document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Apple pen~\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Ugh! Pen Pineapple Apple Pen\n",
      "\n",
      "Metadata:{}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Pineapple pen~\n",
      "\n",
      "Metadata:{}\n"
     ]
    }
   ],
   "source": [
    "embedding_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.75}\n",
    ")\n",
    "docs_after_1st_stage = embedding_retriever.get_relevant_documents('apples')\n",
    "pprint_documents(docs_after_1st_stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æƒ³æƒ³çœ‹** åæ—©æœŸéšæ®µ (stage) æ’åº (ranking) æ³•è·Ÿåå¾ŒæœŸçš„éšæ®µçš„æ’åºæ³•ï¼Œç›®æ¨™æ˜¯æ€éº¼çš„ä¸ä¸€æ¨£ï¼Ÿ\n",
    "<details>\n",
    "<summary>åƒè€ƒ</summary>\n",
    "å‰é¢çš„æ–¹æ³•å´é‡æ–¼åœ¨ä¸è¦èª¤éæ¿¾æ‰ç›¸é—œæ–‡ä»¶çš„å‰æä¸‹ (é‡è¦– Recall)ï¼Œå¦‚ä½•å¿«é€Ÿè€Œä½æˆæœ¬éæ¿¾æ‰å¤§éƒ¨åˆ†çš„æ–‡ä»¶ï¼Œæ¸›å°‘å‚³çµ¦å¾Œé¢é«˜æˆæœ¬æ’åºæ³•çš„æ–‡ä»¶çš„æ•¸é‡ã€‚è¶Šé å¾Œé¢çš„æ–¹æ³•å‰‡æœƒè¶Šå´é‡æ–¼çµ¦å‡ºæº–ç¢ºçš„ç›¸é—œåº¦æ’åº (é‡è¦– Precision)ï¼Œåªç•™ä¸‹çœŸçš„ç›¸é—œçš„æ–‡ä»¶æˆ–çµ¦å‡ºéå¸¸å¥½çš„ç›¸é—œåº¦æ’åºã€‚\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
